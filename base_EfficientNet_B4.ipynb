{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PROFOUNDIVE/AIDHellCamp2/blob/dev2/baseline_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9VMzkxmHvVt"
   },
   "source": [
    "# 6ê³µí•™ê´€ ì¸µ ë¶„ë¥˜í•˜ê¸° - AID ì§€ì˜¥ìº í”„2\n",
    "\n",
    "- ì‘ì„±ëœ í™˜ê²½: Window 11, Pip, Python 3.9, CUDA 11.8, VScode\n",
    "- Google Colab ë“±ì˜ í´ë¼ìš°ë“œ ì»´í“¨íŒ… í™˜ê²½ì—ì„œëŠ” ë‹¤ë¥¸ ë™ì‘ì„ í•  ê°€ëŠ¥ì„± ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA-LxFDEHvVv"
   },
   "source": [
    "## ì‹¤í–‰ ì „ ì‚¬ì „ ì¤€ë¹„\n",
    "\n",
    "### ëª¨ë“ˆ\n",
    "- shellì—ì„œ\n",
    "``` shell\n",
    "# Colab í™˜ê²½ì€ í•„ìš”í•œ ëª¨ë“  ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ ì„¤ì¹˜í•  í•„ìš” x\n",
    "```\n",
    "``` shell\n",
    "# ë³¸ì¸ GPU(CUDA)ì— ë§ëŠ” ë²„ì „ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”\n",
    "# ì°¸ê³ : https://pytorch.org/get-started/locally/\n",
    "# ex1) Pip, CPU í™˜ê²½\n",
    "# pip3 install torch torchvision torchaudio\n",
    "# ex2) Conda, CUDA 12.4 í™˜ê²½\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "```shell\n",
    "pip3 install -U scikit-learn\n",
    "pip3 install -U matplotlib\n",
    "pip3 install tqdm\n",
    "```\n",
    "\n",
    "### ë°ì´í„° íŒŒì¼\n",
    "- ë°ì´í„° íŒŒì¼ì„ root ê²½ë¡œ(baseline_code.ipynbê°€ ìˆëŠ” í´ë”)ì— ì••ì¶•í•´ì œ í•´ì£¼ì„¸ìš”\n",
    "- data link: https://www.kaggle.com/datasets/hyunseok21/jiokdata\n",
    "- colab í™˜ê²½ì´ë¼ë©´ ë‹¤ìŒ [ì±•í„°](#colab-í™˜ê²½ì—ì„œ-kaggleíŒŒì¼-ë‹¤ìš´ë¡œë“œí•˜ê¸°---ë¡œì»¬í™˜ê²½ì´ë¼ë©´-ê±´ë„ˆë›°ê¸°) í™•ì¸í•´ì£¼ì„¸ìš”\n",
    "``` shell\n",
    "ğŸ“root\n",
    " â”œâ”€ğŸ“test\n",
    " â”œâ”€ğŸ“train\n",
    " â”‚  â”œâ”€ğŸ“2F_train\n",
    " â”‚  â”œâ”€ğŸ“3F_train\n",
    " â”‚  â”œâ”€ğŸ“4F_train\n",
    " â”‚  â””â”€ğŸ“5F_train\n",
    " â””â”€ğŸ“œbaseline_code.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvafV0B_HvVw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Colab í™˜ê²½ì—ì„œ kaggleíŒŒì¼ ë‹¤ìš´ë¡œë“œí•˜ê¸° - **ë¡œì»¬í™˜ê²½ì´ë¼ë©´ ê±´ë„ˆë›°ê¸°**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT2CAGawNsuT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "eXvLsRQIHvVw",
    "outputId": "169062ee-c4e4-4a80-e8eb-51ef83540767"
   },
   "outputs": [],
   "source": [
    "# ì‹¤í–‰ ì‹œ ì—…ë¡œë“œ ë²„íŠ¼ í™œì„±í™”\n",
    "# kaggleì—ì„œ ë°œê¸‰ë°›ì€ api keyê°€ ë‹´ê¸´ json íŒŒì¼ ì—…ë¡œë“œ\n",
    "COLAB = True\n",
    "try:\n",
    "  from google.colab import files\n",
    "  files.upload()\n",
    "except:\n",
    "  COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUa0ji1IHvVx"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkKh7-w4HvVx",
    "outputId": "a90a03a9-004d-4fac-b1a5-d612fdb09de0"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  import kagglehub\n",
    "  import shutil\n",
    "\n",
    "  # Download latest version\n",
    "  path = kagglehub.dataset_download(\"hyunseok21/jiokdata\")\n",
    "\n",
    "  print(\"Path to dataset files:\", path)\n",
    "  shutil.move(path+'./train', '/content/')\n",
    "  shutil.move(path+'./test', '/content/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPXNtVgMs-We",
    "outputId": "4f8cb15c-9723-4ee1-e729-a5cab2a4c12d"
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Wypn5NHvVy"
   },
   "source": [
    "# Train Dataë¡œ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e30tzBdzHvVy"
   },
   "source": [
    "## ëª¨ë¸ í•™ìŠµ (with train data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kvtqz_JNHvVy"
   },
   "source": [
    "### ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WC_30jqDHvVy"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI5PWI6wHvVz"
   },
   "source": [
    "### CUDA ì½”ì–´ í…ŒìŠ¤íŠ¸ & í• ë‹¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P3lks_oHvVz",
    "outputId": "ab745907-f018-41ec-a2cd-d6875f3e9b4e"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print(torch.cuda.get_device_name())\n",
    "  print(torch.__version__)\n",
    "  print(torch.version.cuda)\n",
    "  x = torch.randn(1).cuda()\n",
    "  print(x)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxnrzbp3HvV0"
   },
   "source": [
    "### í•˜ì´í¼ íŒŒë¼ë¯¸í„° (Hyper Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmNNietCHvV0"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  # For Train\n",
    "  'epoch': 1,\n",
    "  'batch_size': 32,\n",
    "\n",
    "  # CPU worker\n",
    "  'workers': 8, # ë³¸ì¸ cpu ì“°ë ˆë“œì˜ ì ˆë°˜ ì •ë„\n",
    "\n",
    "  # imgShow\n",
    "  'num_show_img': 5, # ë°ì´í„°ê°€ ì˜ ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸ í•˜ëŠ” ì…€ì—ì„œ ë³´ì—¬ì¤„ ë°ì´í„° ê°œìˆ˜, í•™ìŠµê³¼ ê´€ë ¨ ì—†ìŒ\n",
    "\n",
    "  # For Optimizer\n",
    "  'learning_rate': 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GPLVbFcHvV0"
   },
   "source": [
    "### ì €ì¥í•  í•™ìŠµ ì™„ë£Œ ëª¨ë¸ íŒŒì¼ ì´ë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJVG6OMOHvV0"
   },
   "outputs": [],
   "source": [
    "pt_file_name = 'model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4cniuFfHvV0"
   },
   "source": [
    "### ë°ì´í„° ë¼ë²¨ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4BcCAMnHvV1"
   },
   "outputs": [],
   "source": [
    "class_names = {\n",
    "  \"0\": \"2F\",\n",
    "  \"1\": \"3F\",\n",
    "  \"2\": \"4F\",\n",
    "  \"3\": \"5F\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu1_2UWJomXw"
   },
   "source": [
    "### ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dc4pTo3oolYe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 0) ë‚œìˆ˜ ì‹œë“œ ê³ ì • (ì „ì²´ì ìœ¼ë¡œ ë™ì¼í•œ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥)\n",
    "# ------------------------------------------------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "# torch.backends.cudnn.deterministic = True  # í•„ìš”ì‹œ í™œì„±í™”(í•™ìŠµ ì†ë„â†“, ì™„ì „ ì¬í˜„ì„±â†‘)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1) í•™ìŠµ(train)ìš© ì¦ê°• Transform & ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© Transform ì •ì˜\n",
    "# ------------------------------------------------------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomResizedCrop((380, 380), scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.RandomRotation(degrees=30),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                               saturation=0.2, hue=0.1)\n",
    "    ], p=0.8),  # ì›í•˜ëŠ” í™•ë¥ ë¡œ ë³€í™˜ ì ìš©\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# valid/testì—ì„œëŠ” ì¦ê°•ì„ ì ìš©í•˜ì§€ ì•Šê³ , ë¦¬ì‚¬ì´ì¦ˆ & ì •ê·œí™”ë§Œ ìˆ˜í–‰\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2) ì „ì²´ ImageFolder ë¶ˆëŸ¬ì˜¤ê¸° (transformì€ ì¼ë‹¨ None)\n",
    "#    - ì „ì²´ ì´ë¯¸ì§€ ì¸ë±ìŠ¤(list(range(len(full_dataset))))ë¥¼ ë¨¼ì € êµ¬ë¶„\n",
    "# ------------------------------------------------------------------------\n",
    "full_dataset = datasets.ImageFolder(\n",
    "    root='./train',  # ImageFolder êµ¬ì¡°ì˜ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë”\n",
    "    transform=None   # ë‚˜ì¤‘ì— Subsetìœ¼ë¡œ ê°ê° ë‹¤ë¥¸ transformì„ ì¤„ ì˜ˆì •\n",
    ")\n",
    "\n",
    "all_indices = list(range(len(full_dataset)))\n",
    "print(\"ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜:\", len(full_dataset))\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3) 8:1:1 (train : valid : test) ë¶„í• \n",
    "#    - ì²« ë¶„í• : train 80%, ë‚˜ë¨¸ì§€(tmp) 20%\n",
    "#    - ë‘ ë²ˆì§¸ ë¶„í• : tmp 20% -> valid 10%, test 10%\n",
    "# ------------------------------------------------------------------------\n",
    "train_indices, tmp_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")\n",
    "val_indices, test_indices = train_test_split(\n",
    "    tmp_indices, test_size=0.5, random_state=SEED, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"train ê°œìˆ˜: {len(train_indices)} | valid ê°œìˆ˜: {len(val_indices)} | test ê°œìˆ˜: {len(test_indices)}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4) Subsetì„ í†µí•´ train, valid, testì— ì„œë¡œ ë‹¤ë¥¸ transform ì ìš©\n",
    "#    - train -> train_transform (ì¦ê°• í¬í•¨)\n",
    "#    - valid, test -> eval_transform (ì¦ê°• ì—†ìŒ)\n",
    "#\n",
    "#    ë°©ë²•:\n",
    "#      datasets.ImageFolder(...)ë¥¼ ë‹¤ì‹œ ê°ê° ë§Œë“¤ë˜,\n",
    "#      ë™ì¼í•œ root í´ë”ë¥¼ ì‚¬ìš©í•˜ê³  transformë§Œ ë‹¤ë¥´ê²Œ ì§€ì •.\n",
    "#      ê·¸ë¦¬ê³  Subsetì— (ì›ë³¸ ImageFolder, ì¸ë±ìŠ¤) ì ìš©.\n",
    "# ------------------------------------------------------------------------\n",
    "train_dataset = Subset(\n",
    "    datasets.ImageFolder(root='./train', transform=train_transform),\n",
    "    train_indices\n",
    ")\n",
    "\n",
    "val_dataset = Subset(\n",
    "    datasets.ImageFolder(root='./train', transform=eval_transform),\n",
    "    val_indices\n",
    ")\n",
    "\n",
    "test_dataset = Subset(\n",
    "    datasets.ImageFolder(root='./train', transform=eval_transform),\n",
    "    test_indices\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5) DataLoader ì •ì˜\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        shuffle=True,\n",
    "                        num_workers=params['workers'],\n",
    "                        pin_memory=True),\n",
    "    'valid': DataLoader(val_dataset,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        shuffle=False,\n",
    "                        num_workers=params['workers'],\n",
    "                        pin_memory=True),\n",
    "    'test': DataLoader(test_dataset,\n",
    "                       batch_size=params['batch_size'],\n",
    "                       shuffle=False,\n",
    "                       num_workers=params['workers'],\n",
    "                       pin_memory=True)\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6) ë°°ì¹˜ ìˆ˜ ê³„ì‚° ë° ì¶œë ¥\n",
    "# ------------------------------------------------------------------------\n",
    "batch_num = {\n",
    "    'train': len(dataloaders['train']),\n",
    "    'valid': len(dataloaders['valid']),\n",
    "    'test': len(dataloaders['test'])\n",
    "}\n",
    "\n",
    "print('batch_size: %d | batch_num(train/valid/test): %d / %d / %d' %\n",
    "      (params['batch_size'],\n",
    "       batch_num['train'],\n",
    "       batch_num['valid'],\n",
    "       batch_num['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhP0DZD0HvV1"
   },
   "source": [
    "### Train í•¨ìˆ˜\n",
    "Args:\n",
    "    model: í•™ìŠµí•  ëª¨ë¸.\n",
    "    criterion: ì†ì‹¤ í•¨ìˆ˜.\n",
    "    optimizer: ìµœì í™” ì•Œê³ ë¦¬ì¦˜.\n",
    "    dataloaders: 'train'ê³¼ 'valid' ë‹¨ê³„ì˜ DataLoader.\n",
    "    num_epochs (int): í•™ìŠµí•  ì—í¬í¬ ìˆ˜.\n",
    "    checkpoint_path (str): ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  ê²½ë¡œ.\n",
    "\n",
    "Returns:\n",
    "    model: ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ëª¨ë¸.\n",
    "    best_idx (int): ìµœê³ ì˜ ê²€ì¦ ì •í™•ë„ë¥¼ ë‹¬ì„±í•œ ì—í¬í¬ ë²ˆí˜¸.\n",
    "    best_acc (float): ìµœê³ ì˜ ê²€ì¦ ì •í™•ë„.\n",
    "    train_loss (list): ê° ì—í¬í¬ì˜ í•™ìŠµ ì†ì‹¤.\n",
    "    train_acc (list): ê° ì—í¬í¬ì˜ í•™ìŠµ ì •í™•ë„.\n",
    "    valid_loss (list): ê° ì—í¬í¬ì˜ ê²€ì¦ ì†ì‹¤.\n",
    "    valid_acc (list): ê° ì—í¬í¬ì˜ ê²€ì¦ ì •í™•ë„."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_SMZMsvHvV1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load the model and optimizer from a checkpoint file\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    # Load model state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Load optimizer state dict\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Load best accuracy and epoch\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    epoch = checkpoint['epoch']\n",
    "\n",
    "    return model, optimizer, best_acc, epoch\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders: dict, num_epochs=25, checkpoint_path=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_idx = None  # <-- Needs to be initialized\n",
    "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    start_epoch = 0\n",
    "    if checkpoint_path:\n",
    "        model, optimizer, best_acc, start_epoch = load_checkpoint(model, optimizer, checkpoint_path, device)\n",
    "        print(f\"Resuming training from epoch {start_epoch + 1} with best validation accuracy {best_acc:.1f}%\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):  # Start from the last saved epoch\n",
    "        print()\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}:', '-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluation mode\n",
    "\n",
    "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "            count = 1\n",
    "            pbar_dataloaders = tqdm(dataloaders[phase], desc=phase, ncols=70)\n",
    "            for inputs, labels in pbar_dataloaders:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "                count += 1\n",
    "            pbar_dataloaders.close()\n",
    "\n",
    "            epoch_loss = running_loss / num_cnt\n",
    "            epoch_acc = (running_corrects.double() / num_cnt).cpu() * 100\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.2f} Acc: {epoch_acc:.1f}')\n",
    "\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_idx = epoch + 1\n",
    "                best_acc = epoch_acc\n",
    "                print(f'==> best model saved - Epoch {epoch + 1} / {best_acc:.1f}%')\n",
    "                torch.save({\n",
    "                    'epoch': num_epochs + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                }, pt_file_name)\n",
    "                print('Checkpoint saved')\n",
    "\n",
    "    # Final result\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best valid Acc: Epoch {start_epoch + 1} / {best_acc:.1f}%')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIcwKIsiHvV2"
   },
   "source": [
    "### ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNVJUk3qHvV3"
   },
   "outputs": [],
   "source": [
    "def imgShow(input, title=None):\n",
    "  \"\"\"Img show for Tensor.\"\"\"\n",
    "  input = input.numpy().transpose((1,2,0))\n",
    "  input = np.clip(input, 0, 1)\n",
    "  plt.imshow(input)\n",
    "  if title is not None:\n",
    "    plt.title(title)\n",
    "  plt.pause(0.001) # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "5G6VBhOGHvV3",
    "outputId": "da26d3b4-c1d7-4219-e845-ce90b80d3dbf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs[:params['num_show_img']])\n",
    "imgShow(out, title=[class_names[str(int(x))] for x in classes[:params['num_show_img']]])\n",
    "# valid data\n",
    "inputs, classes = next(iter(dataloaders['valid']))\n",
    "out = torchvision.utils.make_grid(inputs[:params['num_show_img']])\n",
    "imgShow(out, title=[class_names[str(int(x))] for x in classes[:params['num_show_img']]])\n",
    "# test data\n",
    "inputs, classes = next(iter(dataloaders['test']))\n",
    "out = torchvision.utils.make_grid(inputs[:params['num_show_img']])\n",
    "imgShow(out, title=[class_names[str(int(x))] for x in classes[:params['num_show_img']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0V-snMeHvV3"
   },
   "source": [
    "### ëª¨ë¸ì„ ì¥ì¹˜ë¡œ í• ë‹¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8KwQ5k7HvV3",
    "outputId": "9532d39d-6f40-4ed9-8e4c-ba540e324ea1"
   },
   "outputs": [],
   "source": [
    "# EfficientNet model setup\n",
    "from torchvision.models import efficientnet_b4\n",
    "\n",
    "model = efficientnet_b4(pretrained=True)\n",
    "num_classes = 4\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDT5t6tLHvV3"
   },
   "source": [
    "### ì†ì‹¤í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €\n",
    "\n",
    "Adam:\n",
    "ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•´ë„ ì˜ ì‘ë™.  \n",
    "SGD with Momentum:\n",
    "ë°ì´í„°ì…‹ì´ í¬ê±°ë‚˜, ì•ˆì •ì ì¸ í•™ìŠµì´ ì¤‘ìš”í•  ë•Œ ìœ ë¦¬.  \n",
    "AdamW:\n",
    "EfficientNet ë“± ìµœì‹  ì•„í‚¤í…ì²˜ì™€ ì¡°í•© ì‹œ ì¶”ì²œ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMlUIMBpHvV4"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll4E6jvFHvV4"
   },
   "source": [
    "### í•™ìŠµ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1idPP2UnHvV4",
    "outputId": "547e284b-fe8b-4322-ab50-cab9b46d8540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load checkpoint if exists, otherwise train from scratch\n",
    "checkpoint_path = pt_file_name if os.path.exists(pt_file_name) else None\n",
    "\n",
    "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(\n",
    "    model, criterion, optimizer, dataloaders, num_epochs=params['epoch'], checkpoint_path=checkpoint_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5SOTyCVHvV4"
   },
   "source": [
    "## í•™ìŠµ ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "8mqavVrGHvV4",
    "outputId": "38711e5b-ae52-477a-f60e-6c92ef71afed"
   },
   "outputs": [],
   "source": [
    "## ê²°ê³¼ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "print('best model info:\\nModel extracted from epoch %d\\nValid Acc=%1.f / Valid Loss=%.1f'%(best_idx, valid_acc[best_idx-1], valid_loss[best_idx-1]))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot([n for n in range(1,len(train_acc)+1)], train_acc, 'b-', label='train acc')\n",
    "ax1.plot([n for n in range(1,len(valid_acc)+1)], valid_acc, 'r-', label ='valid_acc')\n",
    "plt.plot(best_idx, valid_acc[best_idx-1], 'ro')\n",
    "ax1.set_xlabel('epoch')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('acc', color='k')\n",
    "ax1.tick_params('y', colors='k')\n",
    "plt.legend(bbox_to_anchor=(-0.1, 1.0), loc=\"upper right\")\n",
    "plt.grid()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot([n for n in range(1,len(train_loss)+1)], train_loss, 'g-', label='train loss')\n",
    "ax2.plot([n for n in range(1,len(valid_loss)+1)], valid_loss, 'k-', label='valid loss')\n",
    "plt.plot(best_idx, valid_loss[best_idx-1], 'ro')\n",
    "ax2.set_ylabel('loss', color='k')\n",
    "ax2.tick_params('y', colors='k')\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.0), loc=\"upper left\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HXLtv53HvV9"
   },
   "source": [
    "## ëª¨ë¸ TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E90EexDhHvV9"
   },
   "outputs": [],
   "source": [
    "def test_and_visualize_model(model, dataloaders, phase = 'test', num_images=4):\n",
    "  # phase = 'train', 'valid', 'test'\n",
    "\n",
    "  was_training = model.training\n",
    "  model.eval()\n",
    "\n",
    "  running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "      loss = criterion(outputs, labels) # batchì˜ í‰ê·  loss ì¶œë ¥\n",
    "\n",
    "      running_loss += loss.item() * inputs.size(0)\n",
    "      running_corrects += torch.sum(preds == labels.data)\n",
    "      num_cnt += inputs.size(0) # batch size\n",
    "\n",
    "    test_loss = running_loss / num_cnt\n",
    "    test_acc = running_corrects.double() / num_cnt\n",
    "    print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
    "\n",
    "  # ì˜ˆì‹œ ê·¸ë¦¼ ì¶œë ¥\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "\n",
    "      for j in range(1, num_images+1):\n",
    "        ax = plt.subplot(num_images//2, 2, j)\n",
    "        ax.axis('off')\n",
    "        ax.set_title('%s : %s -> %s' %(\n",
    "          'True' if class_names[str(labels[j].cpu().numpy())] == class_names[str(preds[j].cpu().numpy())] else 'False',\n",
    "          class_names[str(labels[j].cpu().numpy())],\n",
    "          class_names[str(preds[j].cpu().numpy())]\n",
    "        ))\n",
    "        imgShow(inputs.cpu().data[j])\n",
    "\n",
    "      if i == 0: break\n",
    "\n",
    "  model.train(mode=was_training) # ë‹¤ì‹œ trainëª¨ë“œë¡œ ì „í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "c21VSE4LHvV9",
    "outputId": "1f99ccc0-fbf7-4a07-8ae7-ba4e9ed04565"
   },
   "outputs": [],
   "source": [
    "test_and_visualize_model(model, dataloaders, phase='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meb4NRw2HvV9"
   },
   "source": [
    "# Test ë°ì´í„° ë¶„ë¥˜ ë° CSV ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XbI2FyEHvV-"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-QrfLvaHvV-"
   },
   "outputs": [],
   "source": [
    "data_path = './test'\n",
    "image_files = sorted(glob.glob(data_path + '/*'))\n",
    "csv_filename = 'answer.csv'\n",
    "\n",
    "os_name = sys.platform\n",
    "path_split = '/'\n",
    "if os_name.startswith('win'):\n",
    "  path_split = '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qjb1SLhgHvV-"
   },
   "outputs": [],
   "source": [
    "class TestImageDataset(Dataset):\n",
    "  def __init__(self, files, transform):\n",
    "    super().__init__()\n",
    "    self.files = files\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.files)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    file = self.files[index]\n",
    "    try:\n",
    "        img = Image.open(file).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {file}: {e}\")\n",
    "        raise\n",
    "    img = self.transform(img)\n",
    "\n",
    "    return img, file.split(path_split)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkxBb-IrHvV-"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "                        transforms.Resize((380, 380)), # 224x224 ì‚¬ì´ì¦ˆë¡œ ë³€í™˜\n",
    "                        transforms.ToTensor(), # í…ì„œí™”\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw3669KGHvV-"
   },
   "outputs": [],
   "source": [
    "test_dataset = TestImageDataset(image_files, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U--nWaMlHvV_"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=params['batch_size'],\n",
    "                         shuffle=False,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg2LU0XbHvV_",
    "outputId": "19dc3d54-d0df-4446-a42c-b1661c470d9c"
   },
   "outputs": [],
   "source": [
    "model_dict = torch.load(pt_file_name, map_location=device)\n",
    "\n",
    "trained_model = efficientnet_b4(pretrained=True)  # pretrained=Trueë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "trained_model.classifier[1] = torch.nn.Linear(trained_model.classifier[1].in_features, num_classes)\n",
    "trained_model.load_state_dict(model_dict['model_state_dict'])\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# CUDA í™•ì¸\n",
    "print(f\"CUDA:{next(trained_model.parameters()).is_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqRqrUsPHvV_"
   },
   "outputs": [],
   "source": [
    "def test_and_make_csv(model, dataloader):\n",
    "  # phase = 'train', 'valid', 'test'\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  answer_csv = 'id,floor\\n'\n",
    "\n",
    "  pbar_dataloaders = tqdm(dataloader,\n",
    "                          desc='Making Csv',\n",
    "                          ncols=70)\n",
    "  with torch.no_grad():\n",
    "    for inputs, filenames in pbar_dataloaders:\n",
    "      inputs = inputs.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "\n",
    "      for j in range(len(preds)):\n",
    "        answer_csv += f'{filenames[j].split(\".\")[0]},{class_names[str(preds[j].cpu().numpy())]}\\n'\n",
    "  pbar_dataloaders.close()\n",
    "\n",
    "  with open(csv_filename, 'w') as file:\n",
    "    file.write(answer_csv)\n",
    "    print(f'{csv_filename}ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpt3uDTwHvV_",
    "outputId": "0eae30d2-c4fa-4c75-d419-0b3eb3cb8019"
   },
   "outputs": [],
   "source": [
    "test_and_make_csv(trained_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6504703,
     "sourceId": 10507024,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:torchdev]",
   "language": "python",
   "name": "conda-env-torchdev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
